%{ 
    Train multilayer perceptron (MLP) architectures.
%} 

layers = [
    featureInputLayer(4807)

    fullyConnectedLayer(3972)
    batchNormalizationLayer
    reluLayer

    fullyConnectedLayer(3136)
    batchNormalizationLayer
    reluLayer

    regressionLayer];

%miniBatchSize = 50;
%options = trainingOptions('adam', ...
%    'MiniBatchSize', miniBatchSize, ...
%    'Shuffle','every-epoch', ...
%    'Plots','training-progress', ...
%    'Verbose',false);

maxEpochs = 100;
miniBatchSize = 100;
epochIntervals = 1;
initLearningRate = 0.1;
learningRateFactor = 0.1;
l2reg = 0.0001;
options = trainingOptions('sgdm', ...
    'Momentum',0.9, ...
    'InitialLearnRate',initLearningRate, ...
    'LearnRateSchedule','piecewise', ...
    'LearnRateDropPeriod',10, ...
    'LearnRateDropFactor',learningRateFactor, ...
    'L2Regularization',l2reg, ...
    'MaxEpochs',maxEpochs ,...
    'MiniBatchSize',miniBatchSize, ...
    'GradientThresholdMethod','l2norm', ...
    'Plots','training-progress', ...
    'GradientThreshold',0.01);

net = trainNetwork(trainds_cell,layers,options)

